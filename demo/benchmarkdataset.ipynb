{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98424677-021c-4dcc-b71f-95329bb207d0",
   "metadata": {},
   "source": [
    "Same as the 1st example, we firstly need to add the toolbox into the search path, prepare the dataset, and hook the preprocessing and filter-bank methods. Because we already download the dataset in the 1st example, the dataset will not be downloaded again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4093df11-0162-4c38-9668-ff0492333a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SSVEPAnalysisToolbox.datasets import BenchmarkDataset\n",
    "from SSVEPAnalysisToolbox.utils.benchmarkpreprocess import (\n",
    "    preprocess, filterbank\n",
    ")\n",
    "dataset = BenchmarkDataset(path = '2016_Tsinghua_SSVEP_database')\n",
    "dataset.regist_preprocess(preprocess)\n",
    "dataset.regist_filterbank(filterbank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c4024a-6dc8-4b78-a056-b99e936961c2",
   "metadata": {},
   "source": [
    "Now, we can prepare the simulation. In this example,\n",
    "\n",
    "1. We only use 9 occiple channels;\n",
    "2. All 40 classes in this dataset are included;\n",
    "3. 5 harmonic components are considered in the SSVEP reference signals;\n",
    "4. The performance with signal lengths from 0.25s to 1.00s will be verified and compared in this example;\n",
    "5. Based on above simulation settings, we will use the build-in function to automatically generate the training and testing trials of the individual recognition with the leave-one-block-out cross validation. Users also can build their own evaluation trials by referring this build-in function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6d2fbf2-e1c2-4af7-93b3-06713c4a8202",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_container = [ dataset ]\n",
    "from SSVEPAnalysisToolbox.utils.benchmarkpreprocess import suggested_ch\n",
    "ch_used = suggested_ch()\n",
    "all_trials = [i for i in range(dataset.trial_num)]\n",
    "harmonic_num = 5\n",
    "tw_seq = [i/100 for i in range(25,100+5,5)]\n",
    "from SSVEPAnalysisToolbox.evaluator import gen_trials_onedataset_individual_diffsiglen\n",
    "trial_container = gen_trials_onedataset_individual_diffsiglen(dataset_idx = 0,\n",
    "                                                             tw_seq = tw_seq,\n",
    "                                                             dataset_container = dataset_container,\n",
    "                                                             harmonic_num = harmonic_num,\n",
    "                                                             trials = all_trials,\n",
    "                                                             ch_used = ch_used,\n",
    "                                                             t_latency = None,\n",
    "                                                             shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9915aa-2e75-428e-b431-4bb22743b11e",
   "metadata": {},
   "source": [
    "Then, we need to initialize the recognition methods for the performance comparisions. In this example, we compare the eTRCA implemented based on the QR decomposition and the least-square framework. For other methods, we only provide the suggested parameters for the Benchmark Dataset for your reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01c0089b-b913-4db5-b568-efcf7e605292",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SSVEPAnalysisToolbox.utils.benchmarkpreprocess import suggested_weights_filterbank\n",
    "weights_filterbank = suggested_weights_filterbank()\n",
    "from SSVEPAnalysisToolbox.algorithms import (\n",
    "    SCCA_qr, SCCA_canoncorr, ECCA, MSCCA, MsetCCA, MsetCCAwithR,\n",
    "    TRCA, ETRCA, MSETRCA, MSCCA_and_MSETRCA, TRCAwithR, ETRCAwithR, SSCOR, ESSCOR,\n",
    "    TDCA,\n",
    "    SCCA_ls, SCCA_ls_qr,\n",
    "    ECCA_ls, ITCCA_ls,\n",
    "    MSCCA_ls,\n",
    "    TRCA_ls, ETRCA_ls,\n",
    "    MsetCCA_ls,\n",
    "    MsetCCAwithR_ls,\n",
    "    TRCAwithR_ls, ETRCAwithR_ls,\n",
    "    MSETRCA_ls,\n",
    "    TDCA_ls\n",
    ")\n",
    "model_container = [\n",
    "                   # SCCA_qr(weights_filterbank = weights_filterbank),\n",
    "                   # SCCA_canoncorr(weights_filterbank = weights_filterbank),\n",
    "                   # MsetCCA(weights_filterbank = weights_filterbank),\n",
    "                   # MsetCCAwithR(weights_filterbank = weights_filterbank),\n",
    "                   # ECCA(weights_filterbank = weights_filterbank),\n",
    "                   # MSCCA(n_neighbor = 12, weights_filterbank = weights_filterbank),\n",
    "                   # SSCOR(weights_filterbank = weights_filterbank),\n",
    "                   # ESSCOR(weights_filterbank = weights_filterbank),\n",
    "                   # TRCA(weights_filterbank = weights_filterbank),\n",
    "                   # TRCAwithR(weights_filterbank = weights_filterbank),\n",
    "                   ETRCA(weights_filterbank = weights_filterbank),\n",
    "                   # ETRCAwithR(weights_filterbank = weights_filterbank),\n",
    "                   # MSETRCA(n_neighbor = 2, weights_filterbank = weights_filterbank),\n",
    "                   # MSCCA_and_MSETRCA(n_neighbor_mscca = 12, n_neighber_msetrca = 2, weights_filterbank = weights_filterbank),\n",
    "                   # TDCA(n_component = 8, weights_filterbank = weights_filterbank, n_delay = 6)\n",
    "                   ETRCA_ls(weights_filterbank = weights_filterbank),\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181ff33d-8021-401c-a0fb-d0b90dd2c9b8",
   "metadata": {},
   "source": [
    "After preparing the dataset, the recognition methods and the simulation settings, we can use the build-in function to run the evaulation. The parameter `n_jobs` is the number of threading. Higher number requires the computer with higher performance. You can adjust this parameter based on your own situation, or set it as `-1` to automatically generate the threading number based on your core number in your CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c654b3da-a121-4f86-925c-49c80f401baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================\n",
      "   Start\n",
      "========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.000%|████████████████████████████████████████████████████████████| 3360/3360 [Time: 4:28:51<00:00]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================\n",
      "   End\n",
      "========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from SSVEPAnalysisToolbox.evaluator import BaseEvaluator\n",
    "evaluator = BaseEvaluator(dataset_container = dataset_container,\n",
    "                          model_container = model_container,\n",
    "                          trial_container = trial_container,\n",
    "                          save_model = False,\n",
    "                          disp_processbar = True)\n",
    "\n",
    "evaluator.run(n_jobs = 5,\n",
    "              eval_train = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4d313e-7c09-4546-9a50-d0eb86590b3d",
   "metadata": {},
   "source": [
    "All simulation results has been stored in `evaluator`. We can save it for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5be74be-6721-42aa-99cd-ee8692f8683c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_file = 'res/benchmarkdataset_evaluator.pkl'\n",
    "evaluator.save(evaluator_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de9d6a7-ba39-43c0-bc77-3af89832ce02",
   "metadata": {},
   "source": [
    "Then, we can use the build-in function to calculate the recognition the accuracy, the ITR, and the confusion matrix. It should be noticed that the following build-in functions are only designed to evaluate the individual recognition performance with the leave-one-block-out cross evaluation. In other words, the training and testing trails must be generated by the function `gen_trials_onedataset_individual_diffsiglen`. Otherwise, you may need to use other build-in functions or write your own calculation functions by referring these build-in functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48211c3c-d490-45cf-ab97-b9a659383ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SSVEPAnalysisToolbox.evaluator import (\n",
    "    cal_performance_onedataset_individual_diffsiglen, \n",
    "    cal_confusionmatrix_onedataset_individual_diffsiglen\n",
    ")\n",
    "acc_store, itr_store = cal_performance_onedataset_individual_diffsiglen(evaluator = evaluator,\n",
    "                                                                         dataset_idx = 0,\n",
    "                                                                         tw_seq = tw_seq,\n",
    "                                                                         train_or_test = 'test')\n",
    "confusion_matrix = cal_confusionmatrix_onedataset_individual_diffsiglen(evaluator = evaluator,\n",
    "                                                                        dataset_idx = 0,\n",
    "                                                                        tw_seq = tw_seq,\n",
    "                                                                        train_or_test = 'test')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dd0faa-4f2c-44e0-88ea-ab368fa2f625",
   "metadata": {},
   "source": [
    "We also can separate the training and testing time from `evaluator`. This part also demonstrates how to get evaluation results from `evaluator`. You can follow the idea to compute the recognition accuracy or ITR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e97ecdec-0a1d-4137-bcdc-5acf1e73a332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_time = np.zeros((len(model_container), len(evaluator.performance_container)))\n",
    "test_time = np.zeros((len(model_container), len(evaluator.performance_container)))\n",
    "for trial_idx, performance_trial in enumerate(evaluator.performance_container):\n",
    "    for method_idx, method_performance in enumerate(performance_trial):\n",
    "        train_time[method_idx, trial_idx] = sum(method_performance.train_time)\n",
    "        test_time[method_idx, trial_idx] = sum(method_performance.test_time_test)\n",
    "train_time = train_time.T\n",
    "test_time = test_time.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dca9f84-61c4-49cd-a7c8-3ce28435e9de",
   "metadata": {},
   "source": [
    "Finally, we can store all results for further analysis. This example will show you how to store all results in `mat` file (MATLAB format). You also can use this function to store results as `np` file (numpy data file). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57c96c2a-4017-4825-a51a-9109eef58df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SSVEPAnalysisToolbox.utils.io import savedata\n",
    "data = {\"acc_store\": acc_store,\n",
    "        \"itr_store\": itr_store,\n",
    "        \"train_time\": train_time,\n",
    "        \"test_time\": test_time,\n",
    "        \"confusion_matrix\": confusion_matrix,\n",
    "        \"tw_seq\":tw_seq,\n",
    "        \"method_ID\": [model.ID for model in model_container]}\n",
    "data_file = 'res/benchmarkdataset_res.mat'\n",
    "savedata(data_file, data, 'mat')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
